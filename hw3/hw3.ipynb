{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TyAsw2JuVfaM"
   },
   "source": [
    "# Homework 3: Coding\n",
    "\n",
    "**Due Monday September 30th, 11:59pm.**\n",
    "\n",
    "**This is an individual assignment.**\n",
    "\n",
    "**Submit hw3.py file to Gradescope (you may submit as many times as you'd like before the deadline).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYCgbkJwVg7r"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import libraries that you might require.\n",
    "\n",
    "DON'T comment out these imports when submitting your final hw3.py file.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ccn-TAICxI50"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FOR COLAB USERS ONLY\n",
    "\n",
    "Run the following code to upload and unzip the data into the Colab environment.\n",
    "\n",
    "Please comment out *everything* in this cell when submitting your .py file.\n",
    "\"\"\"\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# ! unzip hw2_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSmmDxXGV4y5"
   },
   "source": [
    "# Question 3: Kernel Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7yZ037YC4QL"
   },
   "source": [
    "In this question, you are going to implement a Kernel Regression model using Gaussian kernel method. You will reuse the data Data-set-1 in HW2 to do the experiment.\n",
    "\n",
    "Given a training dataset $S=((\\mathbf{x_1}, y_1), \\ldots , (\\mathbf{x_n}, y_n))$, and kernel function $K(\\cdot,\\cdot)$, the predicted value $\\hat{y}$ of an input data $\\mathbf{x}$ is:\n",
    "$$\\hat{y}(\\mathbf{x}) = \\frac{\\sum_{i=1}^n K(\\mathbf{x}, \\mathbf{x_i}) y_i}{\\sum_{i=1}^n K(\\mathbf{x}, \\mathbf{x_i}) }$$, where $K(\\mathbf{x}, \\mathbf{x_i}) = \\text{exp}(\\frac{-||\\mathbf{x} - \\mathbf{x_i}||^2}{\\sigma^2})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pmc4JtiRDScP"
   },
   "source": [
    "## Question 3.1 Build the model.\n",
    "Fill in your code for function **GaussianKernel** and **kernelRegression**. For $\\sigma = \\{0.01, 0.05, 0.1, 0.15, 0.2, 0.5, 1.0\\}$, fill in your code for function **evaluation** to compute the means squared error of the model for each $\\sigma$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzgsvCGsVvmt"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads the data.\n",
    "Please comment out these statements before converting to .py file and submitting.\n",
    "\"\"\"\n",
    "X_test = pd.read_csv('hw2_data/Data-set-1/X_test.txt', header=None).values\n",
    "y_test = pd.read_csv('hw2_data/Data-set-1/y_test.txt', header=None).values\n",
    "X_train = pd.read_csv('hw2_data/Data-set-1/X_train.txt',header=None).values\n",
    "y_train = pd.read_csv('hw2_data/Data-set-1/y_train.txt', header=None).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTAjfAVM7Lc7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# build the model\n",
    "def GaussianKernel(sigma, vec1, vec2):\n",
    "    \"\"\"\n",
    "    Computes the gaussian kernel between two d-dim vectors\n",
    "    Args:\n",
    "        sigma: a single floating number\n",
    "        vec1: numpy vector\n",
    "        vec2: numpy vector\n",
    "    Returns:\n",
    "        distance: a single floating number\n",
    "    \"\"\"\n",
    "    # TODO your code here: Question 3.1\n",
    "    distance = \n",
    "    return distance\n",
    "\n",
    "\n",
    "def kernelRegression(X_train, y_train, X_test, sigma):\n",
    "    \"\"\"\n",
    "    Computes the predicted values for test set X_test based on kernel regression model\n",
    "    Args:\n",
    "        X_train: feature matrix of training set\n",
    "        y_train: truth value of training set\n",
    "        X_test: feature matrix of test set\n",
    "        sigma: hyperparameter for Gaussian kernel\n",
    "    Returns:\n",
    "        y_predict: list of predicted target values for X_test\n",
    "    \"\"\"\n",
    "    # TODO your code here: Question 3.1\n",
    "    # You need to call the function \"GaussianKernel\" here\n",
    "    y_predict = [0]*len(X_test)    # initialzation\n",
    "\n",
    "    return y_predict\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "def evaluation(y_predict, y_true):\n",
    "    \"\"\"\n",
    "    Computes the mean squared error for regression task.\n",
    "    \n",
    "    Args:\n",
    "        y_predict: list of predicted target values\n",
    "        y_true: list or numpy array of true target values\n",
    "    \n",
    "    Returns:\n",
    "        error: a floating point number representing the error for a validation or test set\n",
    "    \"\"\"    \n",
    "    # TODO your code here: Question 3.1\n",
    "    # you can use the sklearn libary mean_squared_error\n",
    "    \n",
    "    error = \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKhXx-ObVicq"
   },
   "source": [
    "## Question 3.2 Analysis of the model.\n",
    "Similar to what you did for HW2, plot a figure for each sigma value of predicted regression line and scatter plot of data points in the test set. Report the sigma value with the smallest MSE for the test set. How the value of sigma affects the kernel regression model? Compare the figures in this question with the figure in question 1.1 of HW2. Describe your findings based on the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ti8Ys2ix_1Ik"
   },
   "outputs": [],
   "source": [
    "# plot the kernel regression result\n",
    "def plotRegression(X_train, y_train, X_test, y_test, y_pred, sigma):\n",
    "    \"\"\"\n",
    "    Plot the predicted regression line and scattor plot of data points in the test set\n",
    "    Args:\n",
    "        sigma: sigma value for Gqussian kernel\n",
    "    Return:\n",
    "        error: mean squared error of the model given the sigma\n",
    "    \"\"\"\n",
    "    error = evaluation(y_pred, y_test)\n",
    "    x = np.linspace(0,1,1000)\n",
    "    y_regression = kernelRegression(X_train, y_train, x, sigma)\n",
    "    \n",
    "    plt.plot(x, y_regression, '-', color = 'red')\n",
    "    plt.scatter(X_test, y_test, alpha = 0.75)\n",
    "    plt.title('Gaussian kernel regression with sigma = ' + str(sigma) + '\\n MSE = ' + str(error))\n",
    "    plt.xlabel('feature value')\n",
    "    plt.ylabel('target value')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def main(X_train, y_train, X_test, y_test, sigma_set):\n",
    "    \"\"\"\n",
    "    Build the Gaussian kernel regression for each sigma in sigma_set, and then plot the result\n",
    "    \"\"\"\n",
    "\n",
    "    for sigma in sigma_set:\n",
    "        y_pred = kernelRegression(X_train, y_train, X_test, sigma)\n",
    "        plotRegression(X_train, y_train, X_test, y_test, y_pred, sigma)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJVveIQ57fH2"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Finally, we call the main function.\n",
    "Please comment out these statements before converting to .py file and submitting.\n",
    "\"\"\"\n",
    "sigma_set = [0.01, 0.05, 0.1, 0.15, 0.2, 0.5, 1.0]\n",
    "main(X_train, y_train, X_test, y_test, sigma_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfld3QqlkFdf"
   },
   "source": [
    "The answer for quesiton 3.2 should be written on the PDF file that you submit to Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aeHsfeSqlUD"
   },
   "source": [
    "# Question 4: Logistic Regression and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4idcCOhWrWU0"
   },
   "source": [
    "In this question, we will try to use logistic regression to solve a binary classification problem. Given some information of the house, such as area and the number of living rooms, would it be expensive? We would like to predict 1 if it is expensive, and 0 otherwise. \n",
    "\n",
    "We will first implement it with a python package, and then try to implement it by updating weights with gradient descent.Batch gradient descent (since we are using all samples at each iteration) and AdaGrad will be implemented. We will also derive the gradient formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdV0gPZDqlUP"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FOR COLAB USERS ONLY\n",
    "\n",
    "Run the following code to upload and unzip the data into the Colab environment.\n",
    "\n",
    "Please comment out *everything* in this cell (including the import) when submitting your .py file.\n",
    "\"\"\"\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# ! unzip hw3_house_sales.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gR3WFlfqlUS"
   },
   "source": [
    "###4.1 Implement logistic regression with Scikit learn package. \n",
    "\n",
    "First load data and observe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUMEYqDrqlUT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 11)\n",
      "(400, 11)\n",
      "(800, 1)\n",
      "(400, 1)\n",
      "   LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  GrLivArea  \\\n",
      "0    11851            7            5       1990          1990       1442   \n",
      "1     9920            7            5       1996          1997       2013   \n",
      "2    11216            8            5       2006          2006       1489   \n",
      "3     8244            7            5       2004          2004       1720   \n",
      "4    11787            7            5       1996          1997       2398   \n",
      "\n",
      "   FullBath  BedroomAbvGr  KitchenAbvGr  YrSold  const  \n",
      "0         2             3             1    2009      1  \n",
      "1         2             3             1    2007      1  \n",
      "2         2             3             1    2006      1  \n",
      "3         2             3             1    2007      1  \n",
      "4         2             3             1    2007      1  \n",
      "   label\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reads the data.\n",
    "Please comment out these statements before converting to .py file and submitting.\n",
    "\"\"\"\n",
    "\n",
    "X_train = pd.read_csv('hw3_house_sales/X_train.csv')\n",
    "X_test = pd.read_csv('hw3_house_sales/X_test.csv')\n",
    "y_train = pd.read_csv('hw3_house_sales/y_train.csv')\n",
    "y_test = pd.read_csv('hw3_house_sales/y_test.csv')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(X_test.head(5))\n",
    "print(y_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVmVoQfAUkqe"
   },
   "source": [
    "Fill in the logisticRegressionScikit() function. Report the weights, training accuracy, and the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psZtnphuGJSj"
   },
   "outputs": [],
   "source": [
    "def LogisticRegressionScikit(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Computes logistic regression with scikit-learn.\n",
    "    \n",
    "    Args:\n",
    "        X_train: feature matrix of training set\n",
    "        y_train: truth value of training set\n",
    "        X_test: feature matrix of test set\n",
    "        y_test: truth value of test set\n",
    "\n",
    "    Returns:  \n",
    "        w: numpy array of learned coefficients\n",
    "        y_pred: numpy array of predicted labels for the test data\n",
    "        score: accuracy of test data\n",
    "    \"\"\"\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test)\n",
    "    coef = model.coef_\n",
    "    \n",
    "    return coef, y_pred, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GJ7cAepGwqp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.95\n",
      "logistic regression coefficient: [[ 3.27163922e-04  1.95571972e+00  9.66913539e-01  7.06471021e-02\n",
      "  -1.29940635e-03  6.68946735e-03  6.91413286e-01 -9.95880455e-01\n",
      "  -7.41492249e-01 -8.20564385e-02 -4.47207270e-04]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Please comment out these statements before converting to .py file and submitting.\n",
    "\"\"\"\n",
    "coef_scikit, y_pred_scikit, acc_scikit = LogisticRegressionScikit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(acc_scikit))\n",
    "print('logistic regression coefficient:', coef_scikit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8I06kejCVxv8"
   },
   "source": [
    "### 4.3 Logistic regression with simple gradient descent\n",
    "Fill in the LogisticRegressionSGD() function. To do that, two helper functions, sigmoid_activation() (to calculate the sigmoid function result), and model_optimize() (to calculate the gradient of w), will be needed. Both helper functions can be used in the following AdaGrad optimization function. Use a learning rate of $10^{−4}$, run with 2000 iterations. Report the weights and accuracy. Keep track of the accuracy every 100 iterations in the training set. It will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpkEe4mkQ19p"
   },
   "outputs": [],
   "source": [
    "def sigmoid_activation(x):\n",
    "    \"\"\"\n",
    "    Calculates the sigmoid function.\n",
    "    \n",
    "    Args:\n",
    "        x: numpy array of input\n",
    "        \n",
    "    Returns:\n",
    "        final_result: numpy array of sigmoid result\n",
    "    \"\"\"\n",
    "    final_result = \n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9BJvPP71bFs5"
   },
   "source": [
    "**Remember to derive the gradient (Question 4.2), write down the weight update formula, and hand it in with your latex submission!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RGSw2AyQ_kE"
   },
   "outputs": [],
   "source": [
    "def model_optimize(w, X, Y):\n",
    "    \"\"\"\n",
    "    Calculates gradient of the weights.\n",
    "    \n",
    "    Args:\n",
    "        X: numpy array of training samples\n",
    "        Y: numpy array of training labels\n",
    "        w: numpy array of weights\n",
    "    Returns:\n",
    "        dw: the gradient of the weights\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VI5Fdz6ZRUQ9"
   },
   "outputs": [],
   "source": [
    "def LogisticRegressionSGD(w, X, Y, learning_rate, num_iterations):\n",
    "    \"\"\"\n",
    "    Uses SGD to update weights for logistic regression.\n",
    "    \n",
    "    Args:       \n",
    "        w: numpy array of initial weights\n",
    "        X: numpy array of training samples\n",
    "        Y: numpy array of training labels\n",
    "        learning_rate: float learning rate to update w\n",
    "        num_iterations: int number of iterations to update w\n",
    "    \n",
    "    Returns:  \n",
    "        coeff: numpy array of weights after optimization\n",
    "        accuracies: a list of accuracy at each hundred's iteration. With 2000 iterations, \n",
    "                    accuracies should be a list of size 20 \n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    \n",
    "    return coeff, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AQ2M5WETZ4f0"
   },
   "source": [
    "### 4.4 Logistic regression with AdaGrad\n",
    " Fill in the LogisticRegressionAda() function. Use a learning rate of $10^{−4}$, run with 2000 iterations. Report the weights and accuracy. Keep track of the accuracy every 100 iterations in the training set. It will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIO8iOzJRscr"
   },
   "outputs": [],
   "source": [
    "def LogisticRegressionAda(w, X, Y, learning_rate, num_iterations):\n",
    "    \"\"\"\n",
    "    Use AdaGrad to update weights.\n",
    "    \n",
    "    Args:       \n",
    "        w: numpy array of initial weights\n",
    "        X: numpy array of training samples\n",
    "        Y: numpy array of training labels\n",
    "        learning_rate: float learning rate to update w\n",
    "        num_iterations: int number of iterations to update w\n",
    "    \n",
    "    Returns:   \n",
    "        coeff: numpy array of weights after optimization\n",
    "        accuracies: a list of accuracy at each hundred's iteration\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "\n",
    "    return coeff, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TScnzScyaCZM"
   },
   "source": [
    "We add a predict() function here to threshold probability prediction into binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ypERS0E1SLul"
   },
   "outputs": [],
   "source": [
    "def predict(final_pred, m):\n",
    "    \"\"\"\n",
    "    Predict labels from probability to 0/1 label, threshold 0.5.\n",
    "    \n",
    "    Args:\n",
    "        final_pred: m x 1 vector, probabilty of each sample belonging to class 1\n",
    "        m: number of samples\n",
    "        \n",
    "    Returns:\n",
    "        y_pred: m x 1 vector, label of each sample, can be 0/1\n",
    "    \"\"\"\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iLQA1SHAaRQn"
   },
   "source": [
    "Now we start to use our dataset and construct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HHtOjixmSh86"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Please comment out these statements before converting to .py file and submitting.\n",
    "\"\"\"\n",
    "# Do some data preparation, convert dataframe to numpy array\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "w = np.zeros((1, n_features))\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "m_train =  X_train.shape[0]\n",
    "m_test =  X_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-aVaiJzqlU0"
   },
   "source": [
    "Model construction for SGD logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpa3o6VMTdTc"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Please comment out these statements before converting to .py file and submitting.\n",
    "\"\"\"\n",
    "\n",
    "#Gradient Descent\n",
    "coeff_SGD, acc_SGD = LogisticRegressionSGD(w, X_train, y_train, learning_rate=0.0001,num_iterations=2000)\n",
    "\n",
    "# TODO: predict probability\n",
    "final_train_pred_SGD = ...\n",
    "final_test_pred_SGD = ...\n",
    "# predict label\n",
    "y_train_pred_SGD = predict(final_train_pred_SGD, m_train)\n",
    "y_test_pred_SGD = predict(final_test_pred_SGD, m_test)\n",
    "\n",
    "print('Optimized weights for SGD', coeff_SGD[:-1])\n",
    "print('Optimized intercept for SGD', coeff_SGD[-1])\n",
    "\n",
    "print('Training Accuracy for SGD', accuracy_score(y_train_pred_SGD.T, y_train))\n",
    "print('Test Accuracy for SGD', accuracy_score(y_test_pred_SGD.T, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4cSHZdx-amhq"
   },
   "source": [
    "Model construction for AdaGrad logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idXxXj3zTcwp"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Please comment out these statements before converting to .py file and submitting.\n",
    "\"\"\"\n",
    "\n",
    "#AdaGrad Descent\n",
    "coeff_Ada, acc_Ada = LogisticRegressionSGD(w, X_train, y_train, learning_rate=0.0001,num_iterations=2000)\n",
    "\n",
    "# TODO: predict probability\n",
    "final_train_pred_Ada = ...\n",
    "final_test_pred_Ada = ...\n",
    "# predict label\n",
    "y_train_pred_Ada = predict(final_train_pred_Ada, m_train)\n",
    "y_test_pred_Ada = predict(final_test_pred_Ada, m_test)\n",
    "\n",
    "print('Optimized weights for Ada', coeff_Ada[:-1])\n",
    "print('Optimized intercept for Ada', coeff_Ada[-1])\n",
    "\n",
    "print('Training Accuracy for Ada', accuracy_score(y_train_pred_Ada.T, y_train))\n",
    "print('Test Accuracy for Ada', accuracy_score(y_test_pred_Ada.T, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egjfJWHWasSQ"
   },
   "source": [
    "Plot accuracy vs iteration for SGD and AdaGrad. Compare the performance difference. Briefly explain the reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFiMS7M4UEU7"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Please comment out these statements before converting to .py file and submitting.\n",
    "\"\"\"\n",
    "\n",
    "# Plot accuracy vs iteration for SGD and AdaGrad\n",
    "\n",
    "plt.plot(acc_SGD, label='SGD')\n",
    "plt.plot(acc_Ada, label='AdaGrad')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title('Accuracy improvement over time')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJyg0qws0Z4v"
   },
   "source": [
    "What do you observe? Record your comments and explanations under Question 4.5 of your latex document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PCYAcRTVwH3"
   },
   "source": [
    "# Turning it in\n",
    "\n",
    "\n",
    "**Remember to recomment all script portions of this notebook before submitting (i.e. any code not in a function, excluding code that imports libraries). This is to ensure that the Autograder works properly. Also make sure you did not edit other sections of the code outside of specified areas.**\n",
    "\n",
    "1. Download this notebook as a `hw3.py` file with the functions implemented and the sandbox code commented out\n",
    "  - If using Google Colab, go to \"File -> Download .py\"\n",
    "  - If using Jupyter locally, go to \"File -> Download as -> Python (.py)\"\n",
    "  \n",
    "2. Submit `hw3.py` file to Gradescope (you can do this as many times as you'd like before the deadline)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
